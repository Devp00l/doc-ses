<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph.monitor">
 <title>确定群集状态</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>是</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  当群集正在运行时，可以使用 <command>ceph</command> 工具来监视群集。确定群集状态通常涉及检查 OSD、监视器、归置组和元数据服务器的状态。<remark role="fixme">Maybe revert to old version of sentence: Determining the cluster state typically involves
  checking OSD status, monitor status, placement group status and metadata
  server status.</remark>
 </para>
 <tip>
  <title>交互方式</title>
  <para>
   要以交互模式运行 <command>ceph</command> 工具，请在命令行中键入 <command>ceph</command> 并不带任何自变量。如果要在一行中输入多条 <command>ceph</command> 命令，则使用交互模式较为方便。例如：
  </para>
<screen><prompt>cephadm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon_status</screen>
 </tip>
 <sect1 xml:id="monitor.health">
  <title>检查群集运行状况</title>

  <para>
   在启动群集后到开始读取和/或写入数据的期间，检查群集的运行状况：
  </para>

<screen><prompt>root # </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <para>
   Ceph 群集会返回下列运行状况代码之一：
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      一个或多个 OSD 标记为已关闭。OSD 守护程序可能已停止，或对等 OSD 可能无法通过网络连接 OSD。常见原因包括守护程序已停止或已崩溃、主机已关闭或网络中断。
     </para>
     <para>
      校验主机是否运行良好，守护程序是否已启动，并且网络是否正常工作。如果守护程序已崩溃，守护程序日志文件 (<filename>/var/log/ceph/ceph-osd.*</filename>) 可能包含调试信息。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>崩溃类型</replaceable>_DOWN，例如 OSD_HOST_DOWN</term>
    <listitem>
     <para>
      特定 CRUSH 子树中的所有 OSD 均标记为已关闭，例如主机上的所有 OSD。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      在 CRUSH 拓扑图层次结构中引用了 OSD，但它不存在。可使用以下命令从 CRUSH 层次结构中去除 OSD：
     </para>
<screen><prompt>root # </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      <emphasis>backfillfull</emphasis>、<emphasis>nearfull</emphasis>、<emphasis>full</emphasis> 和/或 <emphasis>failsafe_full</emphasis> 的用量阈值没有采用升序。特别是，我们需要 <emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>、<emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis>、<emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis>。可使用以下命令调整阈值：
     </para>
<screen><prompt>root # </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      一个或多个 OSD 超出了 <emphasis>full</emphasis> 阈值，阻止群集处理写入操作。可使用以下命令检查各池的用量：
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
     <para>
      可使用以下命令查看当前定义的 <emphasis>full</emphasis> 比例：
     </para>
<screen><prompt>root # </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      恢复写入可用性的临时办法是稍稍提高 full 阈值：
     </para>
<screen><prompt>root # </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      请通过部署更多 OSD 将新的储存添加到群集，或者删除现有数据来腾出空间。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      一个或多个 OSD 超出了 <emphasis>backfillfull</emphasis> 阈值，因而不允许将数据重新平衡到此设备。这是一条预警，意味着重新平衡可能无法完成，并且群集将满。可使用以下命令检查各池的用量：
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      一个或多个 OSD 超出了 <emphasis>nearfull</emphasis> 阈值。这是一条预警，意味着群集将满。可使用以下命令检查各池的用量：
     </para>
<screen><prompt>root # </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      已设置一个或多个所需的群集标志。除 <emphasis>full</emphasis> 之外，可使用以下命令设置或清除这些标志：
     </para>
<screen><prompt>root # </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>root # </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      这些标志包括：
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         群集标记为已满，无法处理写入操作。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd、pausewr </term>
       <listitem>
        <para>
         已暂停读取或写入。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         不允许 OSD 启动。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         将会忽略 OSD 故障报告，以便监视器不会将 OSD 标记为 <emphasis>down</emphasis>。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         先前标记为 <emphasis>out</emphasis> 的 OSD 将不会在启动时标记回 <emphasis>in</emphasis>。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         <emphasis>关闭</emphasis>的 OSD 在配置间隔过后将不会自动标记为 <emphasis>out</emphasis>。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill、norecover、norebalance</term>
       <listitem>
        <para>
         恢复或数据重新平衡处于暂停状态。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub、nodeep_scrub</term>
       <listitem>
        <para>
         清理处于禁用状态。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         超速缓存分层活动处于暂停状态。
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      一个或多个 OSD 设置了所需的每 OSD 标志。这些标志包括：
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         不允许 OSD 启动。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         将会忽略此 OSD 的故障报告。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         如果此 OSD 先前在发生故障后自动标记为 <emphasis>out</emphasis>，当它启动时将不会标记为 <emphasis>in</emphasis>。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         如果此 OSD 已关闭，则在配置的间隔过后，它将不会自动标记为 <emphasis>out</emphasis>。
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      可使用以下命令来设置和清除每 OSD 标志：
     </para>
<screen><prompt>root # </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>root # </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      CRUSH 拓扑图目前使用的设置很旧，应予以更新。<option>mon_crush_min_required_version</option> 配置选项可确定使用时不会触发此运行状况警告的最旧可调变量（即能够连接到群集的最旧客户端版本）。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      CRUSH 拓扑图目前使用较旧的非最佳方法来计算 straw 桶的中间权重值。应该更新 CRUSH 拓扑图以使用较新的方法 (<option>straw_calc_version</option>=1)。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      一个或多个超速缓存池未配置命中集来跟踪用量，因而阻止分层代理识别要从超速缓存中清理和逐出的冷对象。可使用以下命令对超速缓存池配置命中集：
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      未在运行早于 Luminous 12 版本的 OSD，但是尚未设置 <option>sortbitwise</option> 标志。您需要先设置 <option>sortbitwise</option> 标志，Luminous 12 或更新版本的 OSD 才能启动：
     </para>
<screen><prompt>root # </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      一个或多个池已达到其配额，不再允许写入。可使用以下命令设置池配额和用量：
     </para>
<screen><prompt>root # </prompt>ceph df detail</screen>
     <para>
      您可以使用以下命令提高池配额
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      或者删除一些现有数据以减少用量。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      数据可用性下降，这意味着群集无法处理针对群集中某些数据的潜在读取或写入请求。具体而言，一个或多个 PG 处于不允许处理 IO 请求的状态。有问题的 PG 状态包括<emphasis>互联</emphasis>、<emphasis>陈旧</emphasis>、<emphasis>不完整</emphasis>和缺乏<emphasis>活动</emphasis>（如果这些状况不迅速解决）。运行以下命令可获得有关哪些 PG 受影响的详细信息：
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      大多数情况下，根本原因在于一个或多个 OSD 当前处于关闭状态。可使用以下命令查询特定的有问题 PG 的状态：
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      部分数据的数据冗余降低，这意味着群集没有所需数量的复本用于所有数据（对于副本池）或纠删码分段（对于纠删码池）。具体而言，一个或多个 PG 设置了 <emphasis>degraded</emphasis> 或 <emphasis>undersized</emphasis> 标志（群集中没有该归置组的足够实例），或者有一段时间未设置 <emphasis>clean</emphasis> 标志。运行以下命令可获得有关哪些 PG 受影响的详细信息：
     </para>
<screen><prompt>root # </prompt>ceph health detail</screen>
     <para>
      大多数情况下，根本原因在于一个或多个 OSD 当前处于关闭状态。可使用以下命令查询特定的有问题 PG 的状态：
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      由于群集中的可用空间不足，数据冗余可能已降低，或者某些数据的数据冗余面临风险。具体而言，一个或多个 PG 设置了 <emphasis>backfill_toofull</emphasis> 或 <emphasis>recovery_tooful</emphasis> 标志，这意味着群集无法迁移或恢复数据，原因是一个或多个 OSD 高于 <emphasis>backfillfull</emphasis> 阈值。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      数据清理进程发现群集中存在某些数据一致性问题。具体而言，一个或多个 PG 设置了 <emphasis>inconsistent</emphasis> 或 <emphasis>snaptrim_error</emphasis> 标志（表示某个较早的清理操作发现问题），或者设置了 <emphasis>repair</emphasis> 标志（表示当前正在修复此类不一致问题）。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      最近的 OSD 清理操作发现了不一致问题。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      超速缓存层池将满。在此环境中，“满”由超速缓存池的 <emphasis>target_max_bytes</emphasis> 和 <emphasis>target_max_objects</emphasis> 属性确定。池达到目标阈值时，如果正在从超速缓存清理并逐出数据，写入池的请求可能会被阻止，出现往往会导致延迟很高且性能变差的状态。可使用以下命令调整超速缓存池目标大小：
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      正常的超速缓存清理和逐出活动还可能因基础层可用性或性能下降或整体群集负载而受到限制。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      使用中的 PG 数量低于每 OSD <option>mon_pg_warn_min_per_osd</option> PG 的可配置阈值。这可能导致数据在群集中各 OSD 间的分配和平衡均非最佳，降低整体性能。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      使用中的 PG 数量高于每 OSD <option>mon_pg_warn_max_per_osd</option> PG 的可配置阈值。这可能导致 OSD 守护程序的内存用量较高，群集状态更改（例如 OSD 重启动、添加或去除）之后互联速度降低，并且 Ceph 管理器和 Ceph 监视器上的负载较高。
     </para>
     <para>
      虽然不能降低现有池的 <option>pg_num</option> 值，但是可以降低 <option>pgp_num</option> 值。这样可有效地在相同组的 OSD 上并置一些 PG，从而减轻上述的一些负面影响。可使用以下命令调整 <option>pgp_num</option> 值：
     </para>
<screen><prompt>root # </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      一个或多个池的 <option>pgp_num</option> 值小于 <option>pg_num</option>。这通常表示 PG 计数有所提高，但未同时提升放置行为。使用以下命令设置 <option>pgp_num</option>，使其与触发数据迁移的 <option>pg_num</option> 相匹配，通常便可解决此问题：
     </para>
<screen>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      一个或多个池的每 PG 平均对象数大大高于整体群集平均值。该特定阈值通过 <option>mon_pg_warn_max_object_skew</option> 配置值控制。这通常表示包含群集中大部分数据的池具有的 PG 太少，以及/或者不包含这么多数据的其他池具有的 PG 太多。可通过调整监视器上的 <option>mon_pg_warn_max_object_skew</option> 配置选项提高阈值，来消除该运行状况警告。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED¶</term>
    <listitem>
     <para>
      存在包含一个或多个对象但尚未标记为供特定应用程序使用的池。将池标记为供某个应用程序使用即可消除此警告。例如，如果池由 RBD 使用：
     </para>
<screen><prompt>root # </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      如果池正由自定义应用程序“foo”使用，您还可以使用低级命令标记它：
     </para>
<screen><prompt>root # </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      一个或多个池已达到（或几乎要达到）其配额。触发此错误状况的阈值通过 <option>mon_pool_quota_crit_threshold</option> 配置选项控制。可使用以下命令上调、下调（或去除）池配额：
     </para>
<screen><prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      将配额值设置为 0 将禁用配额。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      一个或多个池接近其配额。触发此警告状况的阈值通过 <option>mon_pool_quota_warn_threshold</option> 配置选项控制。可使用以下命令上调、下调（或去除）池配额：
     </para>
<screen><prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>root # </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      将配额值设置为 0 将禁用配额。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      群集中的一个或多个对象未储存在群集希望用于储存这些对象的节点上。这表示群集最近的某些更改导致的数据迁移尚未完成。误放的数据本身不属于危险状况。数据一致性方面永远不会有风险，仅当所需位置放置了对象所需份数的新副本之后，系统才会删除对象的旧副本。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      找不到群集中的一个或多个对象。具体而言，OSD 知道对象的新副本或已更新副本应该存在，但于当前在线的 OSD 上找不到该版本的对象副本。将阻止对“未找到”对象的读取和写入请求。理想情况下，系统可将具有未找到对象的最近副本的已关闭 OSD 恢复在线状态。可通过负责未找到对象的 PG 的互联状态识别候选 OSD：
     </para>
<screen><prompt>root # </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      正花费很长的时间处理一个或多个 OSD 请求。这可能表示负载极重、储存设备速度缓慢或有软件 Bug。可以从 OSD 主机执行以下命令来查询有问题的 OSD 上的请求队列：
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      可以查看近期最慢的请求摘要：
     </para>
<screen><prompt>root # </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      可使用以下命令查找 OSD 的位置：
     </para>
<screen><prompt>root # </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      已将一个或多个 OSD 请求阻止了很长时间。这表示群集很长一段时间运行状况不佳（例如没有足够的运行中 OSD），或 OSD 存在一些内部问题。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      最近未清理一个或多个 PG。通常每 <option>mon_scrub_interval</option> 秒清理一次 PG，当 <option>mon_warn_not_scrubbed</option> 这类间隔已过但未进行清理时，就会触发此警告。如果 PG 未标记为清理，系统将不会清理它们；如果 PG 放置错误或已降级，就会出现这种情况（请参见上文中的 PG_AVAILABILITY 和 PG_DEGRADED）。可使用以下命令对标记为清理的 PG 手动启动清理：
     </para>
<screen><prompt>root # </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      最近未深度清理一个或多个 PG。通常每 <option>osd_deep_scrub_interval</option> 秒清理一次 PG，当 <option>mon_warn_not_deep_scrubbed</option> 这类间隔已过但未进行清理时，就会触发此警告。如果 PG 未标记为清理，系统将不会（深度）清理它们；如果 PG 放置错误或已降级，就会出现这种情况（请参见上文中的 PG_AVAILABILITY 和 PG_DEGRADED）。可使用以下命令对标记为清理的 PG 手动启动清理：
     </para>
<screen><prompt>root # </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    如果之前为您的配置或密钥环指定了非默认位置，则此时可以指定它们的位置：
   </para>
<screen><prompt>root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor.watch">
  <title>监视群集</title>

  <para>
   可以使用 <command>ceph -s</command> 了解群集的即时状态。例如，由一个监视器和两个 OSD 组成的微型 Ceph 群集可在某工作负载正在运行时列显以下内容：
  </para>

<screen>cluster:
  id:     6586341d-4565-3755-a4fd-b50f51bee248
  health: HEALTH_OK

services:
  mon: 3 daemons, quorum blueshark1,blueshark2,blueshark3
  mgr: blueshark3(active), standbys: blueshark2, blueshark1
  osd: 15 osds: 15 up, 15 in

data:
  pools:   8 pools, 340 pgs
  objects: 537 objects, 1985 MB
  usage:   23881 MB used, 5571 GB / 5595 GB avail
  pgs:     340 active+clean

io:
  client:   100 MB/s rd, 26256 op/s rd, 0 op/s wr</screen>

  <para>
   输出内容提供了以下信息：
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     群集 ID
    </para>
   </listitem>
   <listitem>
    <para>
     群集运行状况
    </para>
   </listitem>
   <listitem>
    <para>
     监视器运行图元版本和监视器仲裁的状态
    </para>
   </listitem>
   <listitem>
    <para>
     OSD 运行图元版本和 OSD 的状态
    </para>
   </listitem>
   <listitem>
    <para>
     归置组运行图版本
    </para>
   </listitem>
   <listitem>
    <para>
     归置组和池数量
    </para>
   </listitem>
   <listitem>
    <para>
     所储存数据<emphasis>理论上的</emphasis>数量和所储存对象的数量；以及
    </para>
   </listitem>
   <listitem>
    <para>
     所储存数据的总量。
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Ceph 计算数据用量的方式</title>
   <para>
    <literal>used</literal> 值反映实际使用的原始储存量。<literal>xxx GB / xxx GB</literal> 值表示群集整体储存容量的可用容量（两者中较小的数字）。理论数量反映在复制、克隆所储存数据或创建其快照前这些数据的大小。因此，实际储存的数据量通常会超出理论上的储存量，因为 Ceph 会创建数据的复本，可能还会将储存容量用于克隆和创建快照。
   </para>
  </tip>
  <para>
   显示即时状态信息的其他命令如下：
  </para>
  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>
  <para>
   要获得实时更新的信息，请将以上任何命令（包括 <command>ceph -s</command>）放置在等待循环中，例如：
  </para>
  <screen><systemitem class="username">root</systemitem>while true ; do ceph -s ; sleep 10 ; done</screen>
  <para>
   如果您观察累了，请按 <keycombo><keycap function="control"/><keycap>C</keycap></keycombo>。
  </para>
 </sect1>
 <sect1 xml:id="monitor.stats">
  <title>检查群集的用量统计数字</title>

  <para>
   要检查群集的数据用量和在各池中的数据分布，可以使用 <command>df</command> 选项。它类似于 Linux <command>df</command>。执行以下命令：
  </para>

<screen><prompt>root # </prompt>ceph df
GLOBAL:
    SIZE       AVAIL      RAW USED     %RAW USED
    55886G     55826G       61731M          0.11
POOLS:
    NAME         ID     USED      %USED     MAX AVAIL     OBJECTS
    testpool     1          0         0        17676G           0
    ecpool       2      4077M      0.01        35352G        2102
    test1        3          0         0        17676G           0
    rbd          4         16         0        17676G           3
    rbd1         5         16         0        17676G           3
    ecpool1      6      5708M      0.02        35352G        2871</screen>

  <para>
   输出的 <literal>GLOBAL</literal> 段落提供群集用于数据的储存量概览。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>SIZE</literal>：群集的整体储存容量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal>：群集中可以使用的可用空间容量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal>：已用的原始储存量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal>：已用的原始储存量百分比。将此数字与 <literal>full ratio</literal> 和 <literal>near full ratio</literal> 搭配使用，可确保您不会用完群集的容量。有关其他细节，请参见<link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/mon-config-ref#storage-capacit">储存容量</link>。
    </para>
    <note>
     <title>群集填充程度</title>
     <para>
      原始储存填充程度达到 70% 到 80% 表示必须向群集添加新的储存。较高的用量可能导致单个 OSD 填满，群集运行状况出现问题。
     </para>
     <para>
      使用命令 <command>ceph osd df tree</command> 可列出所有 OSD 的填充程度。
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   输出的 <literal>POOLS</literal> 段落提供了池列表和每个池的理论用量。此段落的输出<emphasis>不</emphasis>反映复本、克隆数据或快照。例如，如果您储存含有 1MB 数据的对象，理论用量将是 1MB，但是根据复本、克隆数据或快照数量，实际用量可能是 2MB 或更多。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>NAME</literal>：池的名称。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal>：池 ID。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>：以千字节 (KB) 为单位的已储存数据的理论数量 (KB)，如果该数字附加了 M，则以兆字节为单位，如果附加了 G，则以千兆字节为单位。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>%USED</literal>：每个池已用储存的理论百分比。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal>：给定池中的最大可用空间。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal>：每个池所储存对象的理论数量。
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    POOLS 段落中的数字是理论上的。它们不包括复本、快照或克隆数量。因此，USED 和 %USED 数量之和不会加总到输出内容 %GLOBAL 段落中的 RAW USED 和 %RAW USED 数量中。
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor.status">
  <title>检查群集的状态</title>

  <para>
   要检查群集的状态，请执行以下命令：
  </para>

<screen><prompt>root # </prompt>ceph status</screen>

  <para>
   或者
  </para>

<screen><prompt>root # </prompt>ceph -s</screen>

  <para>
   在交互模式下，键入 <command>status</command>，然后按 <keycap function="enter"/>。
  </para>

<screen>ceph&gt; status</screen>

  <para>
   Ceph 将列显群集状态。例如，由一个监视器和两个 OSD 组成的微型 Ceph 群集可能会列显以下内容：
  </para>

<screen>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</screen>
 </sect1>
 <sect1 xml:id="monitor.osdstatus">
  <title>检查 OSD 状态</title>

  <para>
   可通过执行以下命令来检查 OSD，以确保它们已启动且正在运行：
  </para>

<screen><prompt>root # </prompt>ceph osd stat</screen>

  <para>
   或者
  </para>

<screen><prompt>root # </prompt>ceph osd dump</screen>

  <para>
   还可以根据 OSD 在 CRUSH 拓扑图中的位置查看 OSD。
  </para>

<screen><prompt>root # </prompt>ceph osd tree</screen>

  <para>
   Ceph 将列显 CRUSH 树及主机、它的 OSD、OSD 是否已启动及其权重。
  </para>

<screen># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</screen>
 </sect1>
 <sect1 xml:id="storage.bp.monitoring.fullosd">
  <title>检查填满的 OSD</title>

  <para>
   Ceph 可阻止您向填满的 OSD 写入数据，以防丢失数据。在正常运行的群集中，当群集接近其填满比例时，您会收到警告。<command>mon osd full ratio</command> 默认设为容量的 0.95 (95%)，达到该比例后，群集会阻止客户端写入数据。<command>mon osd nearfull ratio</command> 默认设为容量的 0.85 (85%)，达到该比例时，群集会生成运行状况警告。
  </para>

  <para>
   可通过 <command>ceph health</command> 命令报告填满的 OSD 节点：
  </para>

<screen>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   或者
  </para>

<screen>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   处理填满的群集的最佳方法是添加新的 OSD 节点，以让群集将数据重新分布到新的可用储存。
  </para>

  <para>
   如果 OSD 因填满而无法启动，您可以通过删除已满 OSD 中的一些归置组目录来删除一些数据。
  </para>

  <tip>
   <title>防止 OSD 填满</title>
   <para>
    OSD 变满（即用完 100% 的磁盘空间）之后，通常会迅速崩溃而不发出警告。管理 OSD 节点时需记住下面几点提示。
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      每个 OSD 的磁盘空间（通常装入 <filename>/var/lib/ceph/osd/osd-{1,2..}</filename> 下）需放置在专用的底层磁盘或分区上。
     </para>
    </listitem>
    <listitem>
     <para>
      检查 Ceph 配置文件，确保 Ceph 不会将其日志文件储存在专供 OSD 使用的磁盘/分区上。
     </para>
    </listitem>
    <listitem>
     <para>
      确保没有其他进程写入专供 OSD 使用的磁盘/分区。
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor.monstatus">
  <title>检查监视器状态</title>

  <para>
   如果群集有多个监视器（这是很有可能的），则应在启动群集之后到读取和/或写入数据之前的期间检查监视器仲裁状态。多个监视器正在运行时，仲裁必须存在。您还应该定期检查监视器状态，确保它们正在运行。
  </para>

  <para>
   要显示监视器运行图，请执行以下命令：
  </para>

<screen><prompt>root # </prompt>ceph mon stat</screen>

  <para>
   或者
  </para>

<screen><prompt>root # </prompt>ceph mon dump</screen>

  <para>
   要检查监视器群集的仲裁状态，请执行以下命令：
  </para>

<screen><prompt>root # </prompt>ceph quorum_status</screen>

  <para>
   Ceph 将返回仲裁状态。例如，由三个监视器组成的 Ceph 群集可能返回以下内容：
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "127.0.0.1:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "127.0.0.1:6790\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "127.0.0.1:6791\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor.pgroupstatus">
  <title>检查归置组状态</title>

  <para>
   归置组会将对象映射到 OSD。监视归置组时，您希望它们处于 <literal>active</literal> 和 <literal>clean</literal> 状态。有关详细的讨论内容，请参见<link xlink:href="http://docs.ceph.com/docs/master/rados/operations/monitoring-osd-pg">监视 OSD 和归置组</link>。
  </para>
 </sect1>
 <sect1 xml:id="monitor.adminsocket">
  <title>使用管理套接字</title>

  <para>
   <remark role="fixme">Maybe give an example use case? No obvious difference to normal ceph command?!</remark>Ceph 管理套接字可让您通过套接字接口查询守护程序。默认情况下，Ceph 套接字驻留在 <filename>/var/run/ceph</filename> 下。要通过管理套接字访问守护程序，请登录运行守护程序的主机，并使用以下命令：
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable></screen>

  <para>
   要查看可用的管理套接字命令，请执行以下命令：
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable> help</screen>

  <para>
   管理套接字命令可让您在运行时显示和设置您的配置。有关细节，请参见<link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf#ceph-runtime-config">在运行时查看配置</link>。
  </para>

  <para>
   另外，您还可以直接在运行时设置配置（管理套接字会绕过监视器，这与 <command>ceph tell</command>
   <replaceable>daemon-type</replaceable>.<replaceable>id</replaceable> injectargs 不同，后者依赖于监视器，但不需要您直接登录有问题的主机）。
  </para>
 </sect1>
</chapter>
