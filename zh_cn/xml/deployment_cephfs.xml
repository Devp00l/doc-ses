<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_cephfs.xml" version="5.0" xml:id="cha.ceph.as.cephfs">

 <title>安装 CephFS</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>编辑</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>yes</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Ceph 文件系统 (CephFS) 是 POSIX 兼容的文件系统，它使用 Ceph 储存群集来储存其数据。CephFS 使用与 Ceph 块设备相同的群集系统：Ceph 对象储存及其 S3 和 Swift API 或本机绑定 (<systemitem>librados</systemitem>)。
 </para>
 <para>
  要使用 CephFS，需有一个正在运行的 Ceph 储存群集，并至少要有一台正在运行的 <emphasis>Ceph 元数据服务器</emphasis>。
 </para>
 <sect1 xml:id="ceph.cephfs.limitations">
  <title>支持的 CephFS 方案和指导</title>

  <para>
   借助 SUSE Enterprise Storage，SUSE 引入了对使用扩展和分布式组件 CephFS 的众多方案的正式支持。本节介绍硬性限制，并提供有关建议用例的指导。
  </para>

  <para>
   支持的 CephFS 部署必须符合以下要求：
  </para>

  <itemizedlist>
   <listitem>
    <para>
     至少有一台元数据服务器。SUSE 建议部署多个具有 MDS 角色的节点。其中只有一个节点是“主动”节点，其余节点是“被动”节点。从客户端装入 CephFS 时，请记得在 <command>mount</command> 命令中指定所有 MDS 节点。
    </para>
   </listitem>
   <listitem>
    <para>
     在此版本中，CephFS 快照默认已禁用，不受支持。
    </para>
   </listitem>
   <listitem>
    <para>
     客户端基于 SUSE Linux Enterprise Server 12 SP2 或 SP3，使用 <literal>cephfs</literal> 内核模块驱动程序。不支持 FUSE 模块。
    </para>
   </listitem>
   <listitem>
    <para>
     CephFS 支持 <link xlink:href="http://docs.ceph.com/docs/jewel/cephfs/file-layouts/"/> 中所述的文件布局更改。但是，尽管文件系统可由任何客户端装入，但无法将新数据池添加到现有的 CephFS 文件系统 (<literal>ceph mds add_data_pool</literal>)。只能在文件系统已卸载时添加这些池。
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="ceph.cephfs.mds">
  <title>Ceph 元数据服务器</title>

  <para>
   Ceph 元数据服务器 (MDS) 储存 CephFS 的元数据。Ceph 块设备和 Ceph 对象储存<emphasis>不</emphasis>使用 MDS。POSIX 文件系统用户可通过 MDS 执行基本命令（例如 <command>ls</command> 或 <command>find</command>），而不会在 Ceph 储存群集上施加巨大的负担。
  </para>

  <sect2 xml:id="ceph.cephfs.mdf.add">
   <title>添加元数据服务器</title>
   <para>
    您可以根据<xref linkend="ceph.install.stack"/>中所述，在初始群集部署过程中部署 MDS；或者根据<xref linkend="salt.adding.nodes"/>中所述，将 MDS 添加到已部署的群集。
   </para>
   <para>
    部署 MDS 后，请在部署 MDS 的服务器的防火墙设置中允许 <literal>Ceph OSD/MDS</literal> 服务：启动 <literal>yast</literal>，导航到<menuchoice> <guimenu>安全性和用户</guimenu> <guimenu>防火墙</guimenu> <guimenu>允许的服务</guimenu> </menuchoice>，然后在<guimenu>要允许的服务</guimenu>下拉菜单中选择 <guimenu>Ceph OSD/MDS</guimenu>。如果不允许在 Ceph MDS 节点中传送完整流量，则即使其他操作可以正常进行，装入文件系统也会失败。
   </para>
  </sect2>

  <sect2 xml:id="ceph.cephfs.mdf.config">
   <title>配置元数据服务器</title>
   <para>
    可以通过在 <filename>ceph.conf</filename> 配置文件中插入相关的选项来微调 MDS 的行为。有关 MDS 相关配置选项的详细列表，请参见 <link xlink:href="http://docs.ceph.com/docs/master/cephfs/mds-config-ref/"/>。
   </para>
   <para>
    有关 MDS 日记程序配置选项的详细列表，请参见 <link xlink:href="http://docs.ceph.com/docs/master/cephfs/journaler/"/>。
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.cephfs.cephfs">
  <title>CephFS</title>

  <para>
   部署至少包含一台 Ceph 元数据服务器的正常 Ceph 储存群集后，可以创建并装入 Ceph 文件系统。请确保客户端可连接到网络，并具有正确的身份验证密钥环。
  </para>

  <sect2 xml:id="ceph.cephfs.cephfs.create">
   <title>创建 CephFS</title>
   <para>
    CephFS 至少需要两个 RADOS 池：一个用于储存<emphasis>数据</emphasis>，另一个用于储存<emphasis>元数据</emphasis>。配置这些池时，可以考虑：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      对元数据池使用较高的复制级别，因为丢失此池中的任何数据都可能会导致整个文件系统不可访问。
     </para>
    </listitem>
    <listitem>
     <para>
      对元数据池使用延迟较低的储存，例如 SSD，因为在客户端上执行文件系统操作时，这样可以改善用户可察觉到的延迟。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    在 <filename>policy.cfg</filename> 中指派 <literal>role-mds</literal> 时，会自动创建所需的池。在设置元数据服务器之前，可以手动创建池 <literal>cephfs_data</literal> 和 <literal>cephfs_metadata</literal>，以手动优化性能。如果这些池已存在，DeepSea 将不会创建它们。
   </para>
   <para>
    有关管理池的详细信息，请参见<xref linkend="ceph.pools"/>。
   </para>
   <para>
    要使用默认设置创建两个需要用于 CephFS 的池（例如“cephfs_data”和“cephfs_metadata”），请运行以下命令：
   </para>
<screen><prompt>root # </prompt>ceph osd pool create cephfs_data <replaceable>pg_num</replaceable>
<prompt>root # </prompt>ceph osd pool create cephfs_metadata <replaceable>pg_num</replaceable></screen>
   <para>
    可以使用 EC 池取代副本池。建议仅针对低性能要求和不经常发生的随机访问（例如冷储存、备份和存档）使用 EC 池。EC 池中的 CephFS 需要启用 Bluestore，并且必须为池设置 <literal>allow_ec_overwrite</literal> 选项。可以运行 <command>ceph osd pool set ec_pool allow_ec_overwrites true</command> 来设置此选项。
   </para>
   <para>
    纠删码会明显增大文件系统操作的开销，尤其是执行小规模更新时。使用纠删码作为容错机制必然会产生这种开销。这种代价抵消了明显减小的储存空间开销。
   </para>
   <para>
    创建池时，可以使用 <command>ceph fs new</command> 命令来启用文件系统：
   </para>
<screen><prompt>root # </prompt>ceph fs new <replaceable>fs_name</replaceable> <replaceable>metadata_pool_name</replaceable> <replaceable>data_pool_name</replaceable></screen>
   <para>
    例如：
   </para>
<screen><prompt>root # </prompt>ceph fs new cephfs cephfs_metadata cephfs_data</screen>
   <para>
    可以通过列出所有可用的 CephFS 来检查是否已创建文件系统：
   </para>
<screen><prompt>root # </prompt><command>ceph</command> <option>fs ls</option>
 name: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]</screen>
   <para>
    创建文件系统后，MDS 将能够进入<emphasis>活动</emphasis>状态。例如，在单个 MDS 系统中：
   </para>
<screen><prompt>root # </prompt><command>ceph</command> <option>mds stat</option>
e5: 1/1/1 up</screen>
   <tip>
    <title>更多主题</title>
    <para>
     可以在<xref linkend="cha.ceph.cephfs"/>中找到特定任务（例如装入、卸载和高级 CephFS 设置）的更多信息。
    </para>
   </tip>
  </sect2>
 </sect1>
</chapter>
