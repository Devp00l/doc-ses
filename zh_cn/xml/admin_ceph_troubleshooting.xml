<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_troubleshooting.xml" version="5.0" xml:id="storage.troubleshooting">
 <title>查错</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>是</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  本章描述您在操作 Ceph 群集时可能会遇到的多种问题。
 </para>
 <sect1 xml:id="storage.bp.report_bug">
  <title>报告软件问题</title>

  <para>
   如果您在运行 SUSE Enterprise Storage 时遇到了某些组件（例如 Ceph 或 RADOS 网关）相关的问题，请将问题报告给 SUSE 技术支持。建议的方法是使用 <command>supportconfig</command> 实用程序。
  </para>

  <tip>
   <para>
    由于 <command>supportconfig</command> 是模块化软件，因此请确保已安装 <systemitem>supportutils-plugin-ses</systemitem> 包。
   </para>
<screen>rpm -q supportutils-plugin-ses</screen>
   <para>
    如果 Ceph 服务器上缺少此包，可使用以下命令安装它
   </para>
<screen>zypper ref &amp;&amp; zypper in supportutils-plugin-ses</screen>
  </tip>

  <para>
   尽管您可以在命令行中使用 <command>supportconfig</command>，但我们建议使用相关的 YaST 模块。在 <link xlink:href="https://www.suse.com/documentation/sles-12/singlehtml/book_sle_admin/book_sle_admin.html#sec.admsupport.supportconfig"/> 上可以找到有关 <command>supportconfig</command> 的更多信息。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.cluster_mntc.rados_striping">
  <title>使用 <command>rados</command> 发送大型对象失败并显示“OSD 已满”</title>

  <para>
   <command>rados</command> 是用于管理 RADOS 对象储存的命令行实用程序。有关更多信息，请参见 <command>man 8 rados</command>。
  </para>

  <para>
   如果您使用 <command>rados</command> 实用程序将大型对象发送到 Ceph 群集，例如
  </para>

<screen>rados -p mypool put myobject /file/to/send</screen>

  <para>
   该对象可能会填满所有相关的 OSD 空间，并导致群集性能出现严重问题。
  </para>

 </sect1>
 <sect1 xml:id="ceph.xfs.corruption">
  <title>XFS 文件系统损坏</title>

  <para>
   在极少见的情况下（例如出现内核 Bug，或硬件损坏/配置不当），由 OSD 用来储存数据的底层文件系统 (XFS) 可能会受损或不可装入。
  </para>

  <para>
   如果您确定硬件没有问题并且系统配置正确，请针对 SUSE Linux Enterprise Server 内核的 XFS 子系统提出 Bug，并将特定的 OSD 标记为已关闭：
  </para>

<screen>ceph osd down <replaceable>OSD identification</replaceable></screen>

  <warning>
   <title>不要格式化或修改受损的设备</title>
   <para>
    尽管使用 <command>xfs_repair</command> 来修复文件系统问题看似合理，但请不要使用它，因为该命令会修改文件系统。OSD 可以启动，但它的运行情况可能不稳定。
   </para>
  </warning>

  <para>
   现在，请运行以下命令来销毁底层磁盘，并重新创建 OSD：
  </para>

<screen>ceph-disk prepare --zap $OSD_DISK_DEVICE $OSD_JOURNAL_DEVICE"</screen>

  <para>
   例如：
  </para>

<screen>ceph-disk prepare --zap /dev/sdb /dev/sdd2</screen>
 </sect1>
 <sect1 xml:id="storage.bp.recover.toomanypgs">
  <title>“每个 OSD 的 PG 过多”状态讯息</title>

  <para>
   如果在运行 <command>ceph status</command> 之后收到<literal>每个 OSD 的 PG 过多</literal>讯息，则表示超出了 <option>mon_pg_warn_max_per_osd</option> 值（默认值为 300）。此值将与每个 OSD 的 PG 数比率进行比较。这意味着群集设置并不是最佳的。
  </para>

  <para>
   创建池后，无法更改 PG 数。尚不包含任何数据的池可以安全删除，然后使用较少数量的 PG 重新创建。如果池中已包含数据，则唯一的解决方法是将 OSD 添加到群集，使每个 OSD 的 PG 数比率变低。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.recover.stuckinactive">
  <title>“<emphasis>nn</emphasis> pg 停滞在非活动状态”状态讯息</title>

  <para>
   如果在运行 <command>ceph status</command> 之后收到<literal>停滞在非活动状态</literal>状态讯息，则表示 Ceph 不知道要将储存的数据复制到何处，因此无法满足复制规则。此问题可能在完成初始 Ceph 设置后立即发生，可自动修复。在其他情况下，出现此问题可能需要进行手动交互，例如激活已断开的 OSD，或者将新的 OSD 添加到群集。在极少见的情况下，降低复制级别可能有所帮助。
  </para>

  <para>
   如果位置组一直处于停滞状态，则您需要检查 <command>ceph osd tree</command> 的输出。输出应采用树型结构，类似于<xref linkend="storage.bp.recover.osddown"/>中的示例。
  </para>

  <para>
   如果 <command>ceph osd tree</command> 的输出过于平坦，如以下示例中所示
  </para>

<screen>ceph osd tree
ID WEIGHT TYPE NAME    UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1      0 root default
 0      0 osd.0             up  1.00000          1.00000
 1      0 osd.1             up  1.00000          1.00000
 2      0 osd.2             up  1.00000          1.00000</screen>

  <para>
   应该检查相关的 CRUSH 拓扑图是否包含树型结构。如果 CRUSH 拓扑图也很平坦，或者不包含上面示例中所示的主机，则可能表示未在群集中正常执行主机名解析。
  </para>
  <para>
   如果层次结构不正确 — 例如，根包含主机，但 OSD 位于顶层，并且本身未指派到主机 — 则您需要将 OSD 移到层次结构中的正确位置。可以使用 <command>ceph osd crush move</command> 和/或 <command>ceph osd crush set</command> 命令实现此目的。有关更多细节，请参见<xref linkend="op.crush"/>。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.recover.osdweight">
  <title>OSD 权重为 0</title>

  <para>
   当 OSD 启动时，系统会给它指派一个权重。权重越高，群集向该 OSD 写入数据的几率就越大。该权重将在群集 CRUSH 拓扑图中指定，或者通过 OSD 的启动脚本计算得出。
  </para>

  <para>
   在某些情况下，OSD 权重的计算值可能会向下舍入到零。这意味着，未安排该 OSD 储存数据，因此不会向其写入数据。发生此情况的原因通常是相应的磁盘太小（小于 15GB），应该更换为更大的磁盘。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.recover.osddown">
  <title>OSD 已关闭</title>

  <para>
   OSD 守护程序的状态要么是正在运行，要么是已停止/关闭。有 3 个一般性的原因会导致 OSD 关闭：
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     硬盘故障。
    </para>
   </listitem>
   <listitem>
    <para>
     OSD 已崩溃。
    </para>
   </listitem>
   <listitem>
    <para>
     服务器已崩溃。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   可运行以下命令来查看 OSD 的详细状态
  </para>

<screen>ceph osd tree
# id  weight  type name up/down reweight
 -1    0.02998  root default
 -2    0.009995   host doc-ceph1
 0     0.009995      osd.0 up  1
 -3    0.009995   host doc-ceph2
 1     0.009995      osd.1 up  1
 -4    0.009995   host doc-ceph3
 2     0.009995      osd.2 down  1</screen>

  <para>
   示例列表显示 <literal>osd.2</literal> 已关闭。然后，可以检查是否已装入 OSD 所在的磁盘：
  </para>

<screen>lsblk -f
 [...]
 vdb
 ├─vdb1               /var/lib/ceph/osd/ceph-2
 └─vdb2</screen>

  <para>
   可以通过检查 OSD 的日志文件 <filename>/var/log/ceph/ceph-osd.2.log</filename> 来跟踪其关闭原因。找到并解决 OSD 未运行的原因之后，请使用以下命令将它启动
  </para>

<screen>sudo systemctl start ceph-osd@2.service</screen>

  <para>
   请记得将 <literal>2</literal> 替换为已停止的 OSD 的实际编号。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.performance.slowosd">
  <title>查找运行缓慢的 OSD</title>

  <para>
   优化群集性能时，识别群集中运行缓慢的储存/OSD 非常重要。原因在于，如果将数据写入（最）缓慢的磁盘，则会拖慢整个写操作，因为它始终要等到所有相关磁盘全部完成。
  </para>

  <para>
   要找到储存瓶颈并不容易。需要检查每一个 OSD 才能找出使写入过程减慢的 OSD。要针对单个 OSD 执行基准测试，请运行：
  </para>

<screen role="ceph_tell_osd_bench"><command>ceph tell</command> <replaceable>osd_id</replaceable> bench</screen>

  <para>
   例如：
  </para>

<screen><prompt>root # </prompt>ceph tell osd.0 bench
 { "bytes_written": 1073741824,
   "blocksize": 4194304,
   "bytes_per_sec": "19377779.000000"}</screen>

  <para>
   然后，需要在每个 OSD 上运行此命令，并与 <literal>bytes_per_sec</literal> 值相比较，以找出（最）缓慢的 OSD。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.recover.clockskew">
  <title>解决时钟偏差警告</title>

  <para>
   所有群集节点中的时间信息必须同步。如果某个节点的时间未完全同步，在检查群集状态时，您可能会收到时钟偏差警告。
  </para>

  <para>
   可使用 NTP 管理时间同步（请参见 <link xlink:href="http://en.wikipedia.org/wiki/Network_Time_Protocol"/>）。设置每个节点，使其时间与一台或多台 NTP 服务器同步，最好是与同组的 NTP 服务器同步。如果节点上仍然出现时间偏差，请执行以下步骤予以修复：
  </para>

<screen>systemctl stop ntpd.service
systemctl stop ceph-mon.target
systemctl start ntpd.service
systemctl start ceph-mon.target</screen>

  <para>
   然后，可以查询 NTP 同级，并使用 <command>sudo ntpq -p</command> 检查时间偏移。
  </para>

  <para>
   Ceph 监视器的时钟需要同步，相互之间的偏差必须控制在 0.05 秒以内。有关更多信息，请参考<xref linkend="Cluster_Time_Setting"/>。
  </para>
 </sect1>
 <sect1 xml:id="storage.bp.performance.net_issues">
  <title>网络问题导致群集性能不佳</title>

  <para>
   还有其他原因导致群集性能变差。其中一个原因可能是网络问题。在这种情况下，您可能会发现群集即将达到仲裁数，OSD 和监视器节点脱机，数据传输耗费很长时间，或者重新连接尝试了很多次。
  </para>

  <para>
   要检查群集性能下降是否由网络问题导致，请检查 <filename>/var/log/ceph</filename> 目录中的 Ceph 日志文件。
  </para>

  <para>
   要解决群集上的网络问题，请重点关注以下几点：
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     基本网络诊断。尝试使用 DeepSea 诊断工具运行程序 <literal>net.ping</literal> 在群集节点之间执行 ping 命令，确定单个接口是否可以连接到特定的接口，并查看平均响应时间。此命令还会报告比平均值要慢得多的任何特定响应时间。例如：
    </para>
<screen><prompt>root@master # </prompt>salt-run net.ping
  Succeeded: 8 addresses from 7 minions average rtt 0.15 ms</screen>
    <para>
     尝试在启用极大帧的情况下验证所有接口：
    </para>
<screen><prompt>root@master # </prompt>salt-run net.jumbo_ping
  Succeeded: 8 addresses from 7 minions average rtt 0.26 ms</screen>
   </listitem>
   <listitem>
    <para>
     网络性能基准测试。尝试使用 DeepSea 的网络性能运行程序 <literal>net.iperf</literal> 来测试节点间的网络带宽。在给定的群集节点上，有许多 <command>iperf</command> 进程（根据 CPU 核心数）作为服务器启动。剩余的群集节点将用作客户端来生成网络流量。将报告所有独立节点 <command>iperf</command> 进程的累积带宽。此值应反映所有群集节点上的最大可实现网络吞吐量。例如：
    </para>
    <screen><prompt>root@master # </prompt>salt-run net.iperf cluster=ceph output=full
192.168.128.1:
    8644.0 Mbits/sec
192.168.128.2:
    10360.0 Mbits/sec
192.168.128.3:
    9336.0 Mbits/sec
192.168.128.4:
    9588.56 Mbits/sec
192.168.128.5:
    10187.0 Mbits/sec
192.168.128.6:
    10465.0 Mbits/sec</screen>
   </listitem>
   <listitem>
    <para>
     检查群集节点上的防火墙设置。确保这些设置不会阻止 Ceph 操作所需的端口/协议。有关防火墙设置的更多信息，请参见<xref linkend="storage.bp.net.firewall"/>。
    </para>
   </listitem>
   <listitem>
    <para>
     检查网卡、电缆或交换机等网络硬件是否正常运行。
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>独立网络</title>
   <para>
    为确保在群集节点之间进行快速安全的网络通讯，请设置一个专供群集 OSD 和监视器节点使用的独立网络。
   </para>
  </tip>
 </sect1>
</chapter>
