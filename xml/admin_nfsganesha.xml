<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"
 xml:id="cha.ceph.nfsganesha">
<!-- ============================================================== -->
 <title>&ganesha;: Export &ceph; Data via NFS</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>editing</dm:status>
   <dm:deadline></dm:deadline>
   <dm:priority></dm:priority>
   <dm:translation></dm:translation>
   <dm:languages></dm:languages>
   <dm:release>SES4</dm:release>
  </dm:docmanager>
 </info>
 <warning os="ses4">
  <title>Technology Preview</title>
  <para>
   As of &storage; 4, &ganesha; is considered a technology preview and is not
   supported.
  </para>
 </warning>
 <para>
  &ganesha; is an NFS server (refer to
  <link
   xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_nfs.html">Sharing
  File Systems with NFS</link> ) that runs in a user address space instead of
  as part of the operating system kernel. With &ganesha; you can plug in your
  own storage mechanism&mdash;such as &ceph;&mdash;and access it from any NFS
  client.
 </para>
 <sect1 xml:id="ceph.nfsganesha.install">
  <title>Installation</title>
  <para>
   For installation instructions, see <xref linkend="cha.as.ganesha" />.
  </para>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.config">
  <title>Configuration</title>
  <para>
   For a list of all parameters available within the configuration file,
   see <command>man ganesha-config</command>.
  </para>
  <para>
   This section includes information to help you configure the &ganesha; server
   to export the cluster data accessible via &rgw; and &cephfs;.
  </para>
  <para>
   &ganesha; configuration is controlled by
   <filename>/etc/ganesha/ganesha.conf</filename>. Note that changes to
   this file are overwritten when &deepsea;
   stage 4 is executed. To persistently change the settings, edit the file
   <filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename> located
   on the &smaster;.
  </para>
  
  <sect2 xml:id="ceph.nfsganesha.config.general">
   <title>Export Section</title>
   <para>
    This section describes how to configure the <literal>EXPORT</literal>
    sections in the <filename>ganesha.conf</filename>.
   </para>
<screen>EXPORT
{
  Export_Id = 1;
  Path = "/";
  Pseudo = "/";
  Access_Type = RW;
  Squash = No_Root_Squash;
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
   <sect3 xml:id="ceph.nfsganesha.config.general.export">
    <title>Export Main Section</title>
    <variablelist>
     <varlistentry>
      <term>Export_Id</term>
      <listitem>
       <para>
        Each export needs to have a unique 'Export_Id' (mandatory)
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Path</term>
      <listitem>
       <para>
        Export path in the related &cephfs; pool (mandatory). This allows
        exporting subfolders from the &cephfs;.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Pseudo</term>
      <listitem>
       <para>
        Target NFS export path (mandatory for NFSv4). It defines under which
        NFS export path the exported data is available.
       </para>
       <para>
        Example: with the value <literal>/cephfs/</literal> and after executing
       </para>
<screen>
&prompt.root;mount <replaceable>GANESHA_IP</replaceable>:/cephfs/ /mnt/
</screen>
       <para>
        the &cephfs; data is available in the folder <filename>/mnt/cephfs/</filename>
        on the client.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Access_Type</term>
      <listitem>
       <para>
        'RO' for read-only access, default is 'None'
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Squash</term>
      <listitem>
       <para>
        NFS squash option
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>FSAL</term>
      <listitem>
       <para>
        Exporting 'File System Abstraction Layer'. See
        <xref linkend="ceph.nfsganesha.config.general.fsal" />.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph.nfsganesha.config.general.fsal">
    <title>FSAL Subsection</title>
<screen>EXPORT
{
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
    <variablelist>
     <varlistentry>
      <term>Name</term>
      <listitem>
       <para>
        Defines which backend &ganesha; uses. Allowed values are
        <literal>CEPH</literal> for &cephfs; or <literal>RGW</literal> for
        &rgw;. Depending on the choice, a <literal>role-mds</literal> or
        <literal>role-rgw</literal> must be defined in the
        <filename>policy.cfg</filename>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
  <sect2 xml:id="ceph.nfsganesha.config.rgw">
   <title>RGW Section</title>
<screen>RGW {
  ceph_conf = "/etc/ceph/ceph.conf";
  name = "name";
  cluster = "ceph";
}</screen>
    <variablelist>
     <varlistentry>
      <term>ceph_conf</term>
      <listitem>
       <para>
        Points to the <filename>ceph.conf</filename> file. When deploying
        with &deepsea;, it is not necessary to change this value.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>name</term>
      <listitem>
       <para>
        The name of the &ceph; client user used by &ganesha;.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>cluster</term>
      <listitem>
       <para>
        Name of the ceph cluster. &productname; 5 currently only supports
        one cluster name, which is by default <literal>ceph</literal>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
  </sect2>

 </sect1>
 <sect1 xml:id="ceph.nfsganesha.customrole">
  <title>Custom &ganesha; Roles</title>
  <para>
   Custom &ganesha; roles for cluster nodes can be defined. These roles are
   then assigned to nodes in the <filename>policy.cfg</filename>. The roles
   allow for:
  </para>
  <itemizedlist>
   <listitem>
    <para>Separated &ganesha; nodes for accessing &rgw; and &cephfs;.</para>
   </listitem>
   <listitem>
    <para>Assigning different &rgw; users to &ganesha; nodes.</para>
    <para>
     Having different &rgw; users enables &ganesha; nodes to access different
     S3 buckets in the &ceph; cluster. S3 buckets can be used for access
     control. Note: S3 buckets are not to be confused with
     &ceph; buckets used in the &crushmap;.
    </para>
   </listitem>
  </itemizedlist>


  <para>
   Use the following procedure to create a new custom &ganesha; profile:
  </para>
  <procedure  xml:id="proc.ceph.nfsganesha.customrole">
   <step>
    <para>
     Edit the <filename></filename>
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.services">
  <title>Starting &ganesha; Related Services</title>

  <para>
   Enable and start the RPC service required by &ganesha;:
  </para>

<screen>sudo systemctl enable rpcbind rpc-statd
sudo systemctl start rpcbind rpc-statd</screen>

  <para>
   Enable and start the &ganesha; service:
  </para>

<screen>sudo systemctl enable nfs-ganesha
sudo systemctl start nfs-ganesha</screen>

  <tip>
   <title>Starting the &ganesha; Service Manually</title>
   <para>
    Instead of using &systemd; targets, you can start &ganesha; manually. The
    following command starts &ganesha; with the debugging information enabled:
   </para>
<screen>sudo /usr/bin/ganesha.nfsd -L /var/log/ganesha.log \
 -f /etc/ganesha/ganesha.conf -N NIV_DEBUG</screen>
  </tip>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.verify">
  <title>Verifying the Exported NFS Share</title>

  <para>
   After you configure and start &ganesha;, you can verify whether the NFS
   shares are exported on the &ganesha; server node:
  </para>

<screen>sudo showmount -e
/ (everything)</screen>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.mount">
  <title>Mounting the Exported NFS Share</title>

  <para>
   To mount the exported NFS share (as configured in
   <xref
    linkend="ceph.nfsganesha.config"/>) on a client host, run:
  </para>

<screen>sudo mount -t nfs -o rw,noatime,sync \
 <replaceable>nfs_ganesha_server_hostname:/ /path/to/local/mountpoint</replaceable></screen>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.more">
  <title>Additional Resources</title>
  <para>
   The original &ganesha; documentation can be found on 
   <link xlink:href="https://github.com/nfs-ganesha/nfs-ganesha/wiki/Docs"/>.
  </para>
 </sect1>
</chapter>
