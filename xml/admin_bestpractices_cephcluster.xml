<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="storage.ceph.cluster">
	<title>&ceph; Cluster Administration</title>
<para>
The chapter gives details about basic administration tasks that you may need to perform on your cluster deployed by using <command>ceph-deploy</command>. The <command>ceph-deploy</command> is a command line utility that provides you with a wide range of subcommands to administrate the &ceph; cluster. Most of the tasks can be performed without the need to stop your cluster. 
</para>
<para>
The general <command>ceph-deply</command> syntax is the following:
</para>
<screen>ceph-deploy <replaceable>subcommands</replaceable> <replaceable>options</replaceable></screen>

<para>
   A list of selected <command>ceph-deploy</command> subcommands follows.
  </para>
<itemizedlist>
	<listitem>		
		<para>
		<command>gatherkeys</command> - the subcommand is used when you are adding monitors,OSDs or MDS to the cluster. it gathers authentication keys for provisioning new nodes. It takes host
      names as arguments. It checks for and fetches <literal>client.admin
      keyring</literal>, monitor keyring and
      <literal>bootstrap-mds/bootstrap-osd</literal> keyring from monitor host. The command syntax is the following:  
		</para>
<screen>ceph-deploy gatherkeys <replaceable>hostname</replaceable></screen>
     <para>
      <replaceable>hostname</replaceable> is the host name of the monitor from
      where keys are to be pulled.
     </para>
	</listitem>
	<listitem>		
		<para>
		<command>mon add</command> - performs all steps required to add a monitor to your cluster, for more details reffer to <xref linkend="Adding.ceph.deploy.monitors"/>. 
		</para>
	</listitem>
	<listitem>		
		<para>
		<command>osd prepare</command>
		</para>
	</listitem>
	<listitem>		
		<para>
		<command>osd activate</command>
		</para>
	</listitem>
	<listitem>		
		<para>
		<command>rgw prepare/activate/create</command>
		</para>
	</listitem>
	<listitem>
	<para>
		<command>purge, purgedata, forgetkeys</command>
	</para>
	</listitem>	
</itemizedlist>


<tip>
   <para>
    Administer &ceph; nodes with <command>ceph-deploy</command> from the admin
    node. Before administering them, always create a new temporary directory
    and <command>cd</command> into it. Then choose one monitor node and gather
    the authentication keys with the <command>gatherkeys</command> subcommand
    from it, and copy the <filename>/etc/ceph/ceph.conf</filename> file from
    the monitor node into the current local directory.
   </para>
<screen>&prompt.cephuser; mkdir ceph_tmp
&prompt.cephuser; cd ceph_tmp
&prompt.cephuser; ceph-deploy gatherkeys ceph_mon_host
&prompt.cephuser; scp ceph_mon_host:/etc/ceph/ceph.conf .</screen>
  </tip>

<sect1 xml:id="ceph.deploy.monitors.managment">
	<title>Monitors Managment by Using <command>ceph-deploy</command></title>
	<para>
Adding monitoring nodes to the cluster or removing nodes from the cluster can be performed by using <command>ceph-deploy</command> in several steps described in following sections. But you need to take the following into account:
</para>
<important>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <command>ceph-deploy</command> restricts you to only install one monitor
      per host.
     </para>
    </listitem>
    <listitem>
     <para>
      We do not recommend mixing monitors and OSDs on the same host.
     </para>
    </listitem>
    <listitem>
     <para>
      For high availability, you should run a production &ceph; cluster with
      <emphasis>at least</emphasis> three monitors.
     </para>
    </listitem>
   </itemizedlist>
  </important>
	<sect2 xml:id="Adding.ceph.deploy.monitors">
		<title>Adding Monitors</title>
<para>
    After you create a cluster and install &ceph; packages to the monitor
    host(s) (see <xref linkend="ceph.install.ceph-deploy"/> for more
    information), you may deploy the monitors to the monitor hosts. You may
    specify more monitor host names in the same command.
   </para>
<screen>ceph-deploy mon create <replaceable>host-name</replaceable></screen>
<para>
When you run the command, the following tasks are performed:
</para>
<orderedlist>
	<listitem>
		<para>
the platform and the distribution of the target host is detected.
</para>
</listitem>
<listitem>
	<para>
the compatibility with of the host name and 
</para>
</listitem>
</orderedlist>
   <note>
    <para>
     When adding a monitor on a host that was not in hosts initially defined
     with the <command>ceph-deploy new</command> command, a <option>public
     network</option> statement needs to be added to the
     <filename>ceph.conf</filename> file.
    </para>
   </note>
	</sect2>
	<sect2 xml:id="Removing.ceph.deploy.monitors">
		<title>Removing Monitors</title>
	</sect2>

</sect1>
<sect1 xml:id="ceph.deploy.OSD.managment">
	<title>OSDs Managment by Using <command>ceph-deploy</command></title>
	<para>
</para>
</sect1>

</chapter>
