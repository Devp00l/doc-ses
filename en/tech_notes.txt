* to test/document ceph, you need at least 3 nodes (5 is better)
 -> installing KVM environment
 1st VM setting:
  IP: 10.121.9.186
  Subnet Mask: /18
  Hostname: lanner-1.arch.suse.de
  DNS: 10.121.0.100
       10.121.0.12
       10.120.0.1
  Gateway: 10.161.0.1

* VM setup need for ceph:
  - create new user 'ceph': 'useradd -d /home/ceph -m ceph' 
  - create a password for her: 'passwd ceph'    # linux
  - sudo command for ceph user: 'visudo' and add 'ceph ALL = (root) NOPASSWD:ALL'
  - on the admin node (lanner), create ssh keys and export them to each VM (as user ceph):
    * 'ssh-keygen' # no passphrase please
    * 'eval `ssh-agent -s`'
    * 'ssh-add'
    * now lanner is able to log in thru ssh without passwd: ssh 'ceph@lanner-1'

 * deploy target nodes
  - add repo for ceph to all nodes
   # zypper ar http://download.suse.de/ibs/Devel:/Storage:/1.0/SLE_12/
  - add repos for SLE 12 from ibs
   # zypper ar http://dist.suse.de/ibs/SUSE:/SLE-12:/GA/standard/
  - refresh soueces
   # zypper ref
  - purge the installation
   ceph# ceph-deploy purge lanner-1.arch.suse.de lanner-2.arch.suse.de lanner-3.arch.suse.de
   ceph# ceph-deploy purgedata lanner-1.arch.suse.de lanner-2.arch.suse.de lanner-3.arch.suse.de
   ceph# ceph-deploy forgetkeys
   ceph# for i in lanner-1.arch.suse.de lanner-2.arch.suse.de lanner-3.arch.suse.de ; do ssh $i sudo rm -rf /etc/ceph/  /var/lib/ceph/; done
   ceph# rm -rf *     # !!!remember you need to be in a clean local subdir!!!
  - from the admin machine (lanner), install ceph on each lanner-* node
   ceph# ceph-deploy install lanner-1.arch.suse.de lanner-2.arch.suse.de lanner-3.arch.suse.de
  - create keys and local config
   ceph# ceph-deploy new lanner-1.arch.suse.de lanner-2.arch.suse.de lanner-3.arch.suse.de
  - change the local ceph.conf:
    add 'public network = 10.121.0.0/16'
    change 'mon_host' to 'mon_host = 10.121.9.186, 10.121.10.186, 10.121.11.186'
  - create monitors
   ceph# ceph-deploy mon create-initial
  ------------------------------------------------------------------
  notes on monitors
  ------------------------------------------------------------------
  (11:07:34) tserong: tbazant, the rule is:
  (11:07:38) tserong: - you need an odd number of mons
  (11:07:47) tserong: - you need at least three mons for production
  (11:07:59) tserong: - one is ok for testing/demos, but is a single point of
  failure otherwise
  (11:08:13) tserong: - the number of mons has nothing at all to do with the
  number of osds
  ------------------------------------------------------------------ 
  minimum w requirements
  ----------------------------
  (and ideally 1 Ghz core per OSD)
  (16:47:36) oms101: or 1Ghz per terrabyte 
  (16:48:19) oms101: and about 1 gb of RAM per OSD
