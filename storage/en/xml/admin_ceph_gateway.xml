<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN"
"novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter id="cha.ceph.gw">
 <title>&ceph; Object Gateway</title>
<!-- 2014-12-12 tbazant: reusing http://ceph.com/docs/master/radosgw/ -->
<!-- 2015-01-22 ke     : now it is mostly based on
     https://wiki.innerweb.novell.com/index.php/SUSE/Storage/rados-gw
-->
 <remark>2015-01-22 ke     : WIP!!!  Now it is mostly based on
     https://wiki.innerweb.novell.com/index.php/SUSE/Storage/rados-gw</remark>
 <para>
  &ceph; Object Gateway is an object storage interface built on top of
  <systemitem>librgw</systemitem> to provide applications with a RESTful
  gateway to &ceph; Storage Clusters. &ceph; Object Storage supports two
  interfaces:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    <emphasis>S3-compatible</emphasis>: Provides object storage
    functionality with an interface that is compatible with a large subset
    of the Amazon S3 RESTful API.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis>Swift-compatible</emphasis>: Provides object storage
    functionality with an interface that is compatible with a large subset
    of the OpenStack Swift API.
   </para>
  </listitem>
 </itemizedlist>
 <para>
  &ceph; Object Storage uses the &ceph; Object Gateway daemon
  (<systemitem>radosgw</systemitem>), which is a FastCGI module for
  interacting with a &ceph; Storage Cluster. Since it provides interfaces
  compatible with OpenStack Swift and Amazon S3, the &ceph; Object Gateway has
  its own user management. &ceph; Object Gateway can store data in the same
  &ceph; Storage Cluster used to store data from &ceph; Filesystem clients or
  &ceph; Block Device clients. The S3 and Swift APIs share a common namespace,
  so you may write data with one API and retrieve it with the other.
 </para>
 <sect1>
  <title>Manual Installation and Service Activation</title>

  <para>
   The &ceph; Object Gateway daemon runs on Apache and FastCGI. An installed
   and configured &ceph; cluster is a prerequisite.
  </para>

  <para>
   To run a &ceph; Object Storage service, install Apache and FastCGI. Then,
   you must install the &ceph; Object Gateway daemon. The &ceph; Object
   Gateway supports 100-continue, but you must install &ceph; builds of
   Apache and FastCGI for 100-continue support. If you plan to run a &ceph;
   Object Storage service with a federated architecture (multiple regions
   and zones), you must also install the synchronization agent.
  </para>

  <procedure>
   <step>
    <para>
     Install Apache, FastCGI, and &rgw;. The following command installs all
     these components:
    </para>
<screen>sudo zypper ref &amp;&amp; sudo zypper in ceph-radosgw</screen>
   </step>
   <step>
    <para>
     Enable the URL rewrite modules for Apache and FastCGI:
    </para>
<screen>sudo a2enmod rewrite fastcgi</screen>
    <para>
<!-- according to
          https://wiki.innerweb.novell.com/index.php/SUSE/Storage/rados-gw -->
     In <filename>fastcgi.conf</filename>, comment the lines <literal>Order
     allow,deny</literal> and <literal>Deny from all</literal> and add the
     line <literal>Require all granted</literal>. This is needed because the
     order directive only applies for Apache version 2.4 or greater.
    </para>
   </step>
   <step>
    <para>
     Create a configuration file for a new Apache virtual host. Then add a
     line for the <literal>ServerName</literal> directive and provide the
     fully qualified domain name of the host where you will install the
     &rgw;.
    </para>
<screen>cd /etc/apache2/vhosts.d
sudo cp vhost.template radosgw.conf
sudo vim radosgw.conf</screen>
   </step>
   <step>
    <para>
     Restart Apache so that the foregoing changes take effect.
    </para>
<screen>sudo systemctl restart apache2.service</screen>
   </step>
  </procedure>

  <para>
   If you enable SSL, set the port to your SSL port (usually 443) and in
   your <filename>rgw.conf</filename> file include the following:
  </para>

<screen>SSLEngine On
SSLCertificateFile /etc/apache2/ssl.crt/server.crt
SSLCertificateKeyFile /etc/apache2/ssl.key/server.key
SetEnv SERVER_PORT_SECURE 443</screen>

  <para>
   For background information about enabling SSL, see the SLES Admin Guide:
   <ulink
 url="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_apache2_ssl.html"/>.
  </para>
 </sect1>
<!-- ============================================================== -->
 <sect1>
  <title>Configuring the &rgw;</title>

<!-- Simple Configuration -->

  <para>
   Several steps are required to configure a &rgw;.
  </para>

  <sect2>
   <title>Basic Configuration</title>
   <para>
    Configuring a &ceph; Object Gateway requires a running &ceph; Storage
    Cluster, and an Apache web server with the FastCGI module. The &ceph;
    Object Gateway is a client of the &ceph; Storage Cluster. As a &ceph;
    Storage Cluster client, it requires:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      A host name for the gateway instance, for example
      <systemitem>gateway</systemitem>.
     </para>
    </listitem>
    <listitem>
     <para>
      A storage cluster user name with appropriate permissions in a keyring.
     </para>
    </listitem>
    <listitem>
     <para>
      Pools to store its data.
     </para>
    </listitem>
    <listitem>
     <para>
      A data directory for the gateway instance.
     </para>
    </listitem>
    <listitem>
     <para>
      An instance entry in the &ceph; Configuration file.
     </para>
    </listitem>
    <listitem>
     <para>
      A configuration file for the web server to interact with FastCGI.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Each instance must have a user name and key to communicate with a &ceph;
    Storage Cluster. In the following steps, we use an admin node to create
    a keyring. Then, we create a client user name and key. Next, we add the
    key to the &ceph; Storage Cluster. Finally, we distribute the keyring to
    the node containing the gateway instance.
   </para>
   <procedure>
    <step>
     <para>
      Create a keyring for the gateway:
     </para>
<screen>sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.radosgw.keyring
sudo chmod +r /etc/ceph/ceph.client.radosgw.keyring</screen>
    </step>
    <step>
     <para>
      Generate a &ceph; Object Gateway user name and key for each instance. As
      an example, we will use the name <systemitem>gateway</systemitem>
      after <systemitem>client.radosgw</systemitem>:
     </para>
<screen>sudo ceph-authtool /etc/ceph/ceph.client.radosgw.keyring \
  -n client.radosgw.gateway --gen-key</screen>
    </step>
    <step>
     <para>
      Add capabilities to the key:
     </para>
<screen>sudo ceph-authtool -n client.radosgw.gateway --cap osd 'allow rwx' \
  --cap mon 'allow rwx' /etc/ceph/ceph.client.radosgw.keyring</screen>
    </step>
    <step>
     <para>
      Once you have created a keyring and key to enable the &ceph; Object
      Gateway with access to the &ceph; Storage Cluster, add the key to your
      &ceph; Storage Cluster. For example:
     </para>
<screen>sudo ceph -k /etc/ceph/ceph.client.admin.keyring auth add client.radosgw.gateway \
  -i /etc/ceph/ceph.client.radosgw.keyring</screen>
    </step>
    <step>
     <para>
      Distribute the keyring to the node with the gateway instance:
     </para>
<screen>sudo scp /etc/ceph/ceph.client.radosgw.keyring  ceph@<replaceable>hostname</replaceable>:/home/ceph
ssh <replaceable>hostname</replaceable>
sudo mv ceph.client.radosgw.keyring /etc/ceph/ceph.client.radosgw.keyring</screen>
    </step>
   </procedure>
  </sect2>

  <sect2>
   <title>Create Pools</title>
   <para>
    &ceph; Object Gateways require &ceph; Storage Cluster pools to store
    specific gateway data. If the user you created has proper permissions,
    the gateway will create the pools automatically. However, ensure that
    you have set an appropriate default number of placement groups per pool
    in the &ceph; configuration file.
   </para>
   <para>
    When configuring a gateway with the default region and zone, the naming
    convention for pools typically omits region and zone naming, but you can
    use any naming convention you prefer. For example:
   </para>
<screen>.rgw
.rgw.root
.rgw.control
.rgw.gc
.rgw.buckets
.rgw.buckets.index
.log
.intent-log
.usage
.users
.users.email
.users.swift
.users.uid</screen>
  </sect2>

  <sect2>
   <title>Adding Gateway Configuration to &ceph;</title>
   <para>
    Add the &ceph; Object Gateway configuration to the &ceph; Configuration
    file. The &ceph; Object Gateway configuration requires you to identify the
    &ceph; Object Gateway instance. Then, specify the host name where you
    installed the &ceph; Object Gateway daemon, a keyring (for use with
    cephx), the socket path for FastCGI and a log file. For example:
   </para>
<screen>[client.radosgw.<replaceable>instance-name</replaceable>]
host = <replaceable>hostname</replaceable>
keyring = /etc/ceph/ceph.client.radosgw.keyring
rgw socket path = /var/run/ceph/ceph.radosgw.<replaceable>instance-name</replaceable>.fastcgi.sock
log file = /var/log/radosgw/client.radosgw.<replaceable>instance-name</replaceable>.log</screen>
   <para>
    The <literal>[client.radosgw.*]</literal> portion of the gateway
    instance identifies this portion of the &ceph; configuration file as
    configuring a &ceph; Storage Cluster client where the client type is a
    &ceph; Object Gateway (i.e., radosgw). The instance name follows. For
    example:
   </para>
<screen>[client.radosgw.gateway]
host = ceph-gateway
keyring = /etc/ceph/ceph.client.radosgw.keyring
rgw socket path = /var/run/ceph/ceph.radosgw.gateway.fastcgi.sock
log file = /var/log/radosgw/client.radosgw.gateway.log</screen>
   <note>
    <para>
     The host must be your machine hostname, not the FQDN. The name you use
     for the FastCGI socket is not the same as the one used for the object
     gateway, which is
     <literal>ceph-client.radosgw.<replaceable>instance-name</replaceable>.asok</literal>
     by default. Use the same name in your S3 FastCGI file, too.
    </para>
   </note>
   <para>
    Then turn off <literal>print continue</literal>. If you have it set to
    true, you may encounter problems with PUT operations:
   </para>
<screen>rgw print continue = false</screen>
<!-- Enabling Subdomain S3 Calls -->
   <para>
    To use a &ceph; Object Gateway with subdomain S3 calls (e.g.,
    <literal>http://bucketname.hostname</literal>), you must add the &ceph;
    Object Gateway DNS name under the
    <literal>[client.radosgw.gateway]</literal> section of the &ceph;
    configuration file:
   </para>
<screen>[client.radosgw.gateway]
...
rgw dns name = <replaceable>hostname</replaceable></screen>
   <para>
    You should also consider installing a DNS server such as Dnsmasq on your
    client machine(s) when using the
    <literal>http://<replaceable>bucketname</replaceable>.<replaceable>hostname</replaceable></literal>
    syntax. The <filename>dnsmasq.conf</filename> file should include the
    following settings:
   </para>
<screen>address=/<replaceable>hostname</replaceable>/<replaceable>host-ip-address</replaceable>
listen-address=<replaceable>client-loopback-ip</replaceable></screen>
   <para>
    Then, add the <replaceable>client-loopback-ip</replaceable> IP address
    as the first DNS nameserver on the client machine(s).
   </para>
  </sect2>

  <sect2>
   <title>Redeploy &ceph; Configuration</title>
   <para>
    Use <command>ceph-deploy</command> to push a new copy of the
    configuration to the hosts in your cluster:
   </para>
<screen>ceph-deploy config push <replaceable>host-name [host-name]...</replaceable></screen>
  </sect2>

  <sect2>
   <title>Add a &ceph; Object Gateway Script</title>
   <para>
    Add a <filename>s3gw.fcgi</filename> file (use the same name referenced
    in the first line of <filename>rgw.conf</filename>). Save the file to
    the <filename>/srv/www/fastcgi</filename> directory. Assuming a cluster
    named <systemitem>ceph</systemitem> (default), and the user created in
    previous steps, the contents of the file should include:
   </para>
<screen>#!/bin/sh
exec /usr/bin/radosgw -c /etc/ceph/ceph.conf -n client.radosgw.gateway</screen>
   <para>
    Apply execute permissions to <filename>s3gw.fcgi</filename>:
   </para>
<screen>sudo chmod +x s3gw.fcgi</screen>
   <para>
    Also change the ownership to the apache user.
   </para>
<screen>sudo chown wwwrun:www s3gw.fcgi</screen>
  </sect2>

  <sect2>
   <title>Create Data Directory</title>
   <para>
    Deployment scripts may not create the default &ceph; Object Gateway data
    directory. Create data directories for each instance of a radosgw daemon
    if not already done. The <literal>host</literal> variables in the &ceph;
    configuration file determine which host runs each instance of a radosgw
    daemon. The typical form specifies the radosgw daemon, the cluster name
    and the daemon ID.
   </para>
<screen>sudo mkdir -p /var/lib/ceph/radosgw/<replaceable>cluster</replaceable>-<replaceable>id</replaceable></screen>
   <para>
    Using the exemplary ceph.conf settings above, you would execute the
    following:
   </para>
<screen>sudo mkdir -p /var/lib/ceph/radosgw/ceph-radosgw.gateway</screen>
  </sect2>

  <sect2>
   <title>Create a Gateway Configuration</title>
   <para>
    On the host where you installed the &ceph; Object Gateway, create an
    <filename>rgw.conf</filename> file. Place the file in the
    <filename>/etc/apache2/conf.d</filename> directory. You should configure
    Apache to allow encoded slashes, provide paths for log files and to turn
    off server signatures. Here is an exemplary embodiment of a gateway
    configuration:
   </para>
<screen>FastCgiExternalServer /srv/www/fcgi-bin/s3gw.fcgi -socket /var/run/ceph/ceph.radosgw.gateway.fastcgi.sock
&lt;VirtualHost *:80>
ServerName <replaceable>fqdn</replaceable>
ServerAdmin <replaceable>email.address</replaceable>
DocumentRoot /srv/www/fcgi-bin
RewriteEngine On
RewriteRule  ^/(.*) /s3gw.fcgi?%{QUERY_STRING} [E=HTTP_AUTHORIZATION:%{HTTP:Authorization},L]
&lt;IfModule mod_fastcgi.c>
&lt;Directory /srv/www/fcgi-bin>
Options +ExecCGI
AllowOverride All
SetHandler fastcgi-script
Require all granted
AuthBasicAuthoritative Off 
&lt;/Directory>
&lt;/IfModule>
AllowEncodedSlashes On
ErrorLog /var/log/httpd/error.log
CustomLog /var/log/httpd/access.log combined
ServerSignature Off
&lt;/VirtualHost></screen>
   <para>
<!--
      Replace the /{path}/{socket-name} entry with path to the socket and the socket name. For example, /var/run/ceph/ceph.radosgw.gateway.fastcgi.sock.
Ensure that you use the same path and socket name in your ceph.conf
entry.
  -->
    Replace the <replaceable>fqdn</replaceable> entry with the
    fully-qualified domain name of the server. Replace the
    <replaceable>email.address</replaceable> entry with the email address
    for the server administrator. Add a <literal>ServerAlias</literal> if
    you wish to use S3-style subdomains (of course you do). Save the
    configuration to a file (for example, <filename>rgw.conf</filename>).
   </para>
   <para>
    Finally, if you enabled SSL, make sure that you set the port to your SSL
    port (usually 443) and your configuration file includes the following:
   </para>
<screen>SSLEngine on
SSLCertificateFile /etc/apache2/ssl/apache.crt
SSLCertificateKeyFile /etc/apache2/ssl/apache.key
SetEnv SERVER_PORT_SECURE 443</screen>
   <para>
    Enable the fastcgi, rewrite, and ssl modules:
   </para>
<screen>sudo a2enmod fastcgi
sudo a2enmod rewrite
sudo a2enmod ssl</screen>
   <para>
    Change the ownership for <filename>/var/log/apache2</filename> and
    <filename>/var/run/ceph</filename> to ensure that Apache has permissions
    to create a socket or log file:
   </para>
<screen>sudo chown wwwrun:www <replaceable>/path/to/file</replaceable></screen>
  </sect2>

  <sect2>
   <title>Restart Services and Start the Gateway</title>
   <para>
    To ensure that all components have reloaded their configurations, we
    recommend restarting your &ceph; Storage Cluster and Apache services.
    Then, start up the <systemitem>radosgw</systemitem> service.
   </para>
   <para>
    For the &ceph; Storage Cluster, see <xref linkend="cha.ceph.operating"/>.
   </para>
<screen>sudo systemctl restart apache2
sudo systemctl restart ceph-radosgw</screen>
   <para>
    Once the service is up and running, you can make an anonymous GET
    request to see if the gateway returns a response. A simple HTTP request
    to the domain name should return the following:
   </para>
<screen><![CDATA[<ListAllMyBucketsResult>
      <Owner>
              <ID>anonymous</ID>
              <DisplayName/>
      </Owner>
      <Buckets/>
</ListAllMyBucketsResult>]]></screen>
  </sect2>
 </sect1>
 <sect1>
  <title>Managing &rgw; with <command>ceph-deploy</command></title>

  <para>
   The <command>ceph-deploy</command> script includes the
   <literal>rwg</literal> component that helps you manage the &rgw;
   activation and operation.
  </para>

  <para>
   Before running <command>ceph-deploy rgw</command>, you need to have the
   &ceph; cluster installed (see <xref linkend="cha.ceph.install"/> for more
   information).
  </para>

  <procedure>
   <step>
    <para>
     Prepare node(s). You can specify several pairs of
     <replaceable>short_hostname</replaceable>:<replaceable>gateway_name</replaceable>
     to install &rgw; on a required number of nodes.
    </para>
<screen>ceph-deploy --overwrite-conf rgw prepare \
 <replaceable>short_hostname</replaceable>:<replaceable>gateway_name</replaceable> ...</screen>
    <para>
     For example:
    </para>
<screen>ceph-deploy --overwrite-conf rgw prepare ceph-node1:gateway1
[ceph_deploy.cli][INFO  ] Invoked (1.5.19): /usr/bin/ceph-deploy \
  --overwrite-conf rgw prepare ceph-node1:gateway1
[ceph-node1][INFO  ] Running command: sudo ceph -f json auth list
[ceph-node1][INFO  ] Running command: sudo ceph -f json osd lspools
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .users.email 3
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .intent-log 7
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .usage 8
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .users.uid 9
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .rgw.control 10
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .users 11
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .log 12
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .rgw.gc 13
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .users.swift 14
[ceph-node1][INFO  ] Running command: sudo ceph osd pool create .rgw 15
[ceph-node1][INFO  ] Running command: sudo zypper --non-interactive \
  --gpg-auto-import-keys refresh
[ceph-node1][INFO  ] Running command: sudo zypper --non-interactive --quiet \
  install ceph-radosgw
[...]
[ceph_deploy.rgw][INFO  ] Writing:/etc/apache2/conf.d/rgw_80.conf
[ceph_deploy.rgw][INFO  ] Writing:/srv/www/radosgw/s3gw_80.fcgi</screen>
   </step>
   <step>
    <para>
     Activate node(s). Specify the same pairs of
     <replaceable>short_hostname</replaceable>:<replaceable>gateway_name</replaceable>
     you did in when preparing the nodes.
    </para>
<screen>ceph-deploy --overwrite-conf rgw activate \
 <replaceable>short_hostname</replaceable>:<replaceable>gateway_name</replaceable> ...</screen>
    <para>
     For example:
    </para>
<screen>ceph-deploy --overwrite-conf rgw activate ceph-node1:gateway1
[ceph_deploy.cli][INFO  ] Invoked (1.5.19): /usr/bin/ceph-deploy \
  --overwrite-conf rgw activate ceph-node1:gateway1
[ceph-node1][INFO  ] Running command: sudo systemctl start apache2
[ceph-node1][INFO  ] Running command: sudo systemctl enable apache2
[ceph-node1][INFO  ] Running command: sudo systemctl start ceph-radosgw@gateway1
[ceph-node1][INFO  ] Running command: sudo systemctl status ceph-radosgw@gateway1 \
  --output json
[ceph-node1][INFO  ] Running command: sudo systemctl enable ceph-radosgw@gateway1</screen>
    <tip>
     <para>
      To combine the <emphasis>prepare</emphasis> and
      <emphasis>activate</emphasis> steps into one, you can use the
      following command:
     </para>
<screen>ceph-deploy --overwrite-conf rgw create \
 <replaceable>short_hostname</replaceable>:<replaceable>gateway_name</replaceable> ...</screen>
    </tip>
   </step>
  </procedure>

  <para>
   You now have a working &rgw; on the specified nodes. Now you need to give
   access to a client.
  </para>

  <procedure>
   <step>
    <para>
     Create a new user.
    </para>
<screen>sudo radosgw-admin user create \
  --uid=example_user \
  --display-name="Example User" \
  --email=penguin@example.com</screen>
   </step>
   <step>
    <para>
     Generate a secret key for the user.
    </para>
<screen>sudo radosgw-admin key create \
  --gen-secret \
  --subuser=example_user:swift \
  --key-type=swift</screen>
   </step>
   <step>
    <para>
     Both commands will output JSON-formatted data showing the user state.
     Notice the following lines, and remember the
     <literal>secret_key</literal> value:
    </para>
<screen>"swift_keys": [
  { "user": "example_user:swift",
    "secret_key": "r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h"}],</screen>
   </step>
   <step>
    <para>
     On a client node (any host, typically outside the &ceph; cluster),
     install the swift client that understand the &rgw; API.
    </para>
<screen>sudo zypper install python-swiftclient</screen>
   </step>
   <step>
    <para>
     After the swift client is installed, you can run
    </para>
<screen>swift -v -A http://<replaceable>radosgw_host</replaceable>/auth/v1.0 \
  -U <replaceable>username</replaceable>:swift \
  --key='<replaceable>secret_key</replaceable>' \
  stat</screen>
    <para>
     For example:
    </para>
<screen>swift -v -A http://ceph_node1.example.com/auth/v1.0 \
  -U example_user:swift \
  --key='r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h' \
  stat</screen>
   </step>
  </procedure>

  <sect2>
   <title>Removing &rgw; from a Node</title>
   <para>
    To remove a &rgw; installation from the node where it was previously
    installed, run:
   </para>
<screen>ceph-deploy --overwrite-conf rgw delete  \
  <replaceable>short_hostname</replaceable>:<replaceable>gatewayname</replaceable> ...</screen>
   <para>
    For example:
   </para>
<screen>ceph-deploy --overwrite-conf rgw delete ceph-node1:gateway1
[ceph_deploy.cli][INFO] Invoked (1.5.19): /usr/bin/ceph-deploy \
  --overwrite-conf rgw delete ceph-node1:gateway1
[...]
[ceph-node1][INFO] Running command: sudo systemctl stop ceph-radosgw@gateway1
[ceph-node1][INFO] Running command: sudo systemctl disable ceph-radosgw@gateway1
[ceph-node1][INFO] Running command: sudo systemctl stop apache2
[ceph-node1][INFO] Running command: sudo systemctl disable apache2
[ceph-node1][INFO] Running command: sudo ceph -f json auth list
[ceph-node1][INFO] Running command: sudo ceph auth del client.radosgw.gateway1</screen>
   <tip>
    <para>
     You need a copy of the local <command>ceph.conf</command> file, in your
     current working directory. If you do not have a copy of it, copy it
     from your cluster.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Listing &rgw; Installations</title>
   <para>
    To list &rgw; installations with the &ceph; cluster, run:
   </para>
<screen>ceph-deploy rgw list</screen>
  </sect2>
 </sect1>
</chapter>
